{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNA++q5ORv1AOWIZk+qJvw/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-dnY9P1C1ER","outputId":"3ba53f54-d841-4554-9937-3eaac4990115"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 250/1200 [22:05<1:36:01,  6.06s/it]Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 409, in hf_raise_for_status\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/requests/models.py\", line 1024, in raise_for_status\n","    raise HTTPError(http_error_msg, response=self)\n","requests.exceptions.HTTPError: 502 Server Error: Bad Gateway for url: https://router.huggingface.co/nebius/v1/chat/completions\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/tmp/ipython-input-2316079989.py\", line 55, in <cell line: 0>\n","    response = client.chat.completions.create(messages=messages, max_tokens=100)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\", line 923, in chat_completion\n","    data = self._inner_post(request_parameters, stream=stream)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/inference/_client.py\", line 279, in _inner_post\n","    hf_raise_for_status(response)\n","  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\", line 482, in hf_raise_for_status\n","    raise _format(HfHubHTTPError, str(e), response) from e\n","huggingface_hub.errors.HfHubHTTPError: 502 Server Error: Bad Gateway for url: https://router.huggingface.co/nebius/v1/chat/completions\n"," 27%|██▋       | 319/1200 [29:24<1:30:44,  6.18s/it]"]}],"source":["from huggingface_hub import InferenceClient\n","import pandas as pd\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","import base64, os\n","\n","# 📂 Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 📄 Load and sample 1200 rows\n","df = pd.read_csv(\"/content/drive/MyDrive/vision_benchmark/metadata/wildlife_dataset.csv\")\n","sample_df = df.sample(1200, random_state=42).reset_index(drop=True)\n","\n","# 🧠 Model setup\n","client = InferenceClient(\"Qwen/Qwen2.5-VL-72B-Instruct\")\n","\n","# 🏷️ All valid labels\n","known_labels = df[\"label\"].str.lower().unique().tolist()\n","\n","# 🧠 Base64 encoding\n","def encode_image_base64(image_path):\n","    if not os.path.exists(image_path):\n","        raise FileNotFoundError(f\"Image not found: {image_path}\")\n","    with open(image_path, \"rb\") as f:\n","        return \"data:image/jpeg;base64,\" + base64.b64encode(f.read()).decode(\"utf-8\")\n","\n","# 🧠 Extract predicted label from response\n","def extract_predicted_label(response, known_labels):\n","    response = str(response).lower()\n","    for label in known_labels:\n","        if label in response:\n","            return label\n","    return \"unknown\"\n","\n","# 🧪 Run inference\n","results = []\n","\n","for _, row in tqdm(sample_df.iterrows(), total=len(sample_df)):\n","    image_path = row[\"image_path\"]\n","    prompt = row[\"prompt\"]\n","    ground_truth = row[\"label\"].lower()\n","\n","    try:\n","        img_b64 = encode_image_base64(image_path)\n","\n","        messages = [{\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"image_url\", \"image_url\": {\"url\": img_b64}},\n","                {\"type\": \"text\", \"text\": prompt}\n","            ]\n","        }]\n","\n","        response = client.chat.completions.create(messages=messages, max_tokens=100)\n","        answer = response.choices[0].message.content.strip().lower()\n","        predicted_label = extract_predicted_label(answer, known_labels)\n","\n","    except Exception as e:\n","        import traceback\n","        traceback.print_exc()\n","        answer = f\"error: {e}\"\n","        predicted_label = \"unknown\"\n","\n","    results.append({\n","        \"image_path\": image_path,\n","        \"prompt\": prompt,\n","        \"ground_truth\": ground_truth,\n","        \"model_response\": answer,\n","        \"predicted_label\": predicted_label\n","    })\n","\n","# 💾 Save output\n","df_out = pd.DataFrame(results)\n","output_path = \"/content/drive/MyDrive/vision_benchmark/metadata/wildlife_Qwen2.5_result.csv\"\n","df_out.to_csv(output_path, index=False)\n","\n","# 📊 Evaluation (includes 'unknown')\n","f1_macro = f1_score(df_out[\"ground_truth\"], df_out[\"predicted_label\"], average=\"macro\", zero_division=0)\n","f1_micro = f1_score(df_out[\"ground_truth\"], df_out[\"predicted_label\"], average=\"micro\", zero_division=0)\n","\n","print(\"\\n✅ Evaluation Done\")\n","print(f\"F1 Score : {f1_macro:.4f}\")\n","print(f\"F1 Score : {f1_micro:.4f}\")\n"]}]}