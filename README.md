
# ğŸ” VISBENCH-3: Benchmarking MLLMs on Fine-Grained Visual Reasoning Tasks

VISBENCH-3 is a comprehensive benchmark for evaluating **Multimodal Large Language Models (MLLMs)** on challenging fine-grained visual reasoning tasks:

- ğŸ‘¯â€â™€ï¸ **Twin Face Verification**
- ğŸ¥¸ **Disguise Detection**
- ğŸ¾ **Wildlife Species Recognition (Night-vision)**

---

## âœ¨ Highlights

- ğŸ“Š Benchmarked **Qwen2.5-VL**, **LLaMA-4 Maverick**, **LLaMA-4 Scout** across 3 diverse tasks
- ğŸ“ˆ Evaluated using **Accuracy**, **F1 Score**, and **Robustness**
- ğŸ§  Included architectural analysis for each model
- ğŸ“¦ Open-sourced pipeline for replication and extension

---

## ğŸ—ï¸ Architecture Overview

### ğŸ”¹ [Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct)
- Developed by Alibaba.
- Based on the **Transformer decoder** with **Vision and Language fusion** at token-level.
- Accepts **images and text jointly** via a vision encoder + projection to LLM tokens.

### ğŸ”¸ [LLaMA-4 Maverick](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8)
- Metaâ€™s open-weight LLM with **vision support** using embedded visual tokens.
- Uses **dual-encoder fusion** between vision encoder and text decoder.
- Fine-tuned for **multimodal instruction-following**.

### ğŸ”¸ [LLaMA-4 Scout](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct)
- An enhanced LLaMA variant for **instruction-tuned visual reasoning**.
- Integrates attention mechanisms across image patches + text.
- Performs better on **binary vision classification** tasks (like twin/disguise).

---

## ğŸ“Š Evaluation Visuals

### ğŸ”¹ Dataset Difficulty Ranking
![Dataset Difficulty](assets/plot1_difficulty.png)

> Higher F1 â†’ Easier for the model. Twin is easier than Wildlife.

---

### ğŸ”¹ Radar Plot: Overall Model Performance
![Radar All Models](assets/plot2_radar.png)

> LLaMA-Scout consistently ranks highest across all metrics.

---

### ğŸ”¹ F1 Score Trend by Dataset
![F1 Robustness](assets/plot3_f1_trend.png)

> Qwen2.5 degrades more gracefully across difficult datasets.

---

### ğŸ”¹ Accuracy Comparison
![Accuracy Bar](assets/plot4_accuracy.png)

> Scout outperforms on disguise detection; Maverick is stronger on wildlife.

---

### ğŸ”¹ F1 Score Comparison
![F1 Bar](assets/plot5_f1.png)

---

### ğŸ”¹ F1 Table Summary
![F1 Table](assets/plot6_table.png)

> Best average: **LLaMA-Scout (0.6032)**

---

### ğŸ”¹ Best Model Per Dataset (Pie Chart)
![Best Model Pie](assets/plot7_pie.png)

> LLaMA-Scout wins on 2 out of 3 datasets.

---

## ğŸ§ª Dataset Tasks

| Task       | Description                                     |
|------------|--------------------------------------------------|
| Twin       | Classify whether face pairs are real twins       |
| Disguise   | Detect if one image is a disguised version       |
| Wildlife   | Classify animal species from IR night images     |

---

## ğŸš€ Quickstart

```bash
git clone https://github.com/your-username/VISBENCH-3.git
cd VISBENCH-3
pip install -r requirements.txt
python run_benchmark.py --model Qwen2.5-VL --task disguise
```

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ assets/                     # ğŸ“¸ All plots and diagrams
â”œâ”€â”€ data/                       # ğŸ“‚ Datasets for 3 tasks
â”œâ”€â”€ notebooks/                  # ğŸ§  Evaluation scripts
â”œâ”€â”€ src/                        # ğŸ”§ Core benchmark engine
â””â”€â”€ README.md                   # ğŸ“˜ This file
```

---

## ğŸ“ˆ Future Work

- Expand to **video QA**, **multi-turn image chat**, and **VQA reasoning**
- Add evaluation under **distribution shift** and **real-world noise**
- Introduce **human-in-the-loop verification** for borderline cases

---

## ğŸ‘¨â€ğŸ”¬ Authors

- **Kiara** â€” Principal Researcher | UCD MSc | Vision-Language Systems
- **Smart Optimization** â€” Project Lead & Benchmark Design

---

## ğŸ“„ License

MIT License

---

## ğŸ“š Citation

```bibtex
@misc{visbench3,
  title={VISBENCH-3: Fine-Grained Vision Reasoning Benchmark for MLLMs},
  author={Kiara, Smart Optimization},
  year={2025},
  url={https://github.com/your-username/VISBENCH-3}
}
```
